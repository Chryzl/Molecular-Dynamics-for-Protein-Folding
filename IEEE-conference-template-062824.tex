\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{orcidlink}
\hypersetup{
    colorlinks=false,
    pdfborder={0 0 0},
}

\newcommand{\TODO}[1]{\textbf{\textcolor{red}{TODO: #1}}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{
    Investigating Protein Folding Dynamics Using Molecular Dynamics Simulations-based Approaches
}

\author{\IEEEauthorblockN{Christian Nix\,\orcidlink{0009-0006-5718-3452}}
\IEEEauthorblockA{\textit{School of Computation, Information and Technology (CIT)} \\
\textit{Technical University of Munich}\\
Munich, Germany \\
christian.nix@tum.de}
}

\maketitle

\begin{abstract}
\TODO{Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Duis autem vel eum iriure dolor in hendrerit in vulputate velit esse molestie consequat, vel illum dolore eu feugiat nulla facilisis at vero eros et accumsan et iusto odio dignissim qui blandit praesent luptatum zzril delenit augue duis dolore te feugait nulla facilisi.}
\end{abstract}

\begin{IEEEkeywords}
\TODO{Index words to be added in the end.}
\end{IEEEkeywords}

\section{Introduction}
Proteins are fundamental in driving biological processes and form the basic building blocks that life relies on \cite{eisenberg2000protein}. They are pivotal in almost all cellular processes, thus motivating their study in fields such as medicine, chemistry, or biophysics. Proteins play essential roles in regulation, transportation, signaling, immune responses, and metabolism, among others. \cite[pp.~163ff., pp.~225ff.]{buxbaum2007fundamentals} Chemically, proteins are a polymer of 20 canonical amino acids that have unique side-chains giving them unique chemical properties, such as hydrophobicity, charge, or polarity. Neighboring amino acids are linked via peptide bonds formed between their \textit{amino} and carboxyl (\textit{acid}) groups, thus forming the protein's backbone from which their distinct side-chains extend. \cite{stollar2020uncovering}

Protein structure is commonly described as four hierarchical levels: primary, secondary, tertiary, and quaternary structure. The \textit{primary structure} refers to the linear sequence of amino acids in the protein chain. Given the chemical properties of neighboring amino acids, \textit{secondary structure} elements, such as $\alpha$-helices or $\beta$-sheets, can be formed. The secondary structure is stabilized by hydrogen bonds between backbone atoms. The \textit{tertiary structure} describes the overall 3D arrangement of the protein chain, including the side-chains, i.e., the determination of all atoms in 3D space. The tertiary structure is stabilized by a broad set of interactions, such as van der Waals forces, hydrogen bonds, ionic interactions, and disulfide bridges. Finally, some proteins consist of multiple polypeptide chains (i.e., multiple protein subunits), whose arrangement is described by the \textit{quaternary structure}. \cite[pp.~65ff.]{kessel2018introduction}

Generally speaking, protein function, and thus the protein's biochemical role, is determined by its 3D structure, motivating the study of protein structures and how proteins assume these structures \cite{lee2007predicting}. However, proteins are not static entities, but rather dynamic molecules that can undergo conformational changes to perform their functions. Therefore, understanding protein dynamics is crucial for a comprehensive understanding of protein function. \cite{teilum2009functional} Additionally, misfolded proteins can lead to various diseases, such as Alzheimer's, Parkinson's, or cystic fibrosis, further highlighting the importance of understanding protein folding as a dynamic process \cite{valastyan2014mechanisms}.

\subsection{Protein Folding and its Importance}
So far, we have established that knowing the 3D structure of proteins is important for understanding their function and role in biological processes. However, the process of protein folding itself is highly complex and not yet fully understood \cite{tsuboyama2023mega}. Anfinsen's Nobel prize-winning work demonstrated that the primary structure (i.e., the amino acid sequence) of a protein determines its final 3D structure, implying that all information necessary for folding is self-contained \cite{anfinsen1973principles}. However, if a protein were to randomly sample all possible conformations its primary sequence could take, the time required to fold would be much beyond the biologically relevant timescales (milliseconds to seconds) observed in nature \cite{levinthal1969fold, dobson2003protein}. For example, assuming 10 possible configurations per amino acid residue, a small protein of 100 residues would have $10^{100}$ possible conformations. A rotation around a single bond takes roughly $10^{-12}$ s \cite{lee2025ultrafast}, leading to a total time of $10^{88}$ s or roughly $10^{80}$ years to sample all conformations. This discrepancy is known as Levinthal's paradox \cite{levinthal1969fold}. Since we know that proteins do fold on biologically relevant timescales, there must be some guiding principles that direct the folding process efficiently.

To describe the folding process and its driving forces, we make use of the Gibbs free energy $G = H - TS$, where $H$ is the enthalpy, $T$ the temperature, and $S$ the entropy \cite[pp.~76ff.]{AtkinsDePaula2006}. The Gibbs energy is valid, because folding occurs at constant pressure and temperature \cite{ghelis2012protein, pain2000mechanisms, bryngelson1995funnels}. As becomes apparent from the definition of $G$, folding is driven by enthalpic ($H$) and entropic contributions ($TS$). For example, a main driver of folding is the hydrophobic effect, where non-polar residues cluster together \cite{durell2017hydrophobic}. This benefits the enthalpy via van der Waals forces between the residues, but also increases the entropy by releasing ordered water molecules into the bulk solvent \cite[pp.~280ff.]{KlostermeierRudolph2024}. If we now consider the free energy as a function of the protein's conformation, we arrive at the concept of the energy landscape of protein folding. In Levinthal's paradox, the energy landscape was assumed to be flat, with only the native, folded state being energetically favorable, resulting in random searching. During the 1990s, the concept of the energy landscape as a folding funnel was introduced (Figure \ref{fig:intro:funnel}). \cite{bryngelson1995funnels, onuchic1997theory}

\begin{figure}[b]
    \centering
    \input{figures/folding_funnel.tex}
    \caption{\TODO{Temporary Fig} Schematic representation of a high-dimensional protein folding funnel which is a free energy function $G$ of protein conformation $\mathbf{r}$. The native state corresponds to the global minimum of the free energy. Local minima represent meta-stable folding intermediates which originate from conformational changes. Kinetic conversion between minima requires overcoming energy barriers and can thus be slow.}
    \label{fig:intro:funnel}
\end{figure}

As can be seen in Figure \ref{fig:intro:funnel}, the folding funnel concept correctly captures that conformations along a folding pathway do not have the same energy. The idealized funnel shape arises from the assumption that each newly formed native contact (i.e., a contact that exists in the native structure) lowers the free energy, leading to a monotonic decrease in free energy as folding progresses. \cite[pp.~283ff.]{KlostermeierRudolph2024} However, the energy landscape is much more rugged in reality, with many local extrema. For example, conformations stemming from rotating a side-chain may differ by small differences in energy, thus these conformations are interconverted rapidly. On the other hand, larger conformational changes, such as forming or breaking tertiary structure elements, may lead to greater energy changes and therefore result in local minima that are harder to escape from. \cite{bryngelson1995funnels} These local minima, given sufficiently large energy barriers, can lead to meta-stable states and folding intermediates \cite{dill2008protein}.

The protein folding problem is not limited to predicting the final folded structure, but is also interested in understanding the folding pathways, i.e., the process by which a protein transitions from its unfolded to folded state through these various intermediates and meta-stable states \cite{eaton2000fast}. Ground-breaking methods such as AlphaFold \cite{senior2020improvedAF1, jumper2021highlyAF2, abramson2024accurateAF3} have essentially solved the prediction of the final folded structure, although they do not reveal \emph{how} proteins reach that state \cite{outeiral2022current}. Importantly, proteins do not necessarily fold via a single, well-defined pathway, but can utilize multiple pathways to reach the native state \cite{sridevi2004increasing}. As a result, we must identify not only the final native state, but also the various folding intermediates along the pathways and determine the kinetics of folding, i.e., the rates at which transitions between conformational states occur, especially those that are rate-limiting and therefore control the overall folding speed \cite{gelman2014fast}.

\subsection{Studying Protein Folding Dynamics}
\label{sec:intro:studying_folding}
Until the 1990s, protein folding dynamics were primarily studied experimentally using \textit{stopped-flow} techniques, which allowed a temporal resolution of around 1 ms \cite{gibson19696}. At the same time, atomistic molecular dynamics (MD) simulations were limited to nanosecond timescales. As a result, all (at the time) described protein folding events occurred on timescales inaccessible to MD simulations. \cite{eaton2021modern} However, the development of laser-based temperature-jump (T-jump) techniques enabled the experimental study of protein folding on nanosecond timescales \cite{phillips1995ultrafast}. Nonetheless, T-jump experiments cannot provide information about the underlying conformational rearrangements as they report only global relaxation kinetics \cite{eaton2021modern}. In contrast, experimental methods such as F√∂rster resonance energy transfer (FRET) can yield insights into the distances between specific residues, thus providing some structural information \cite{schuler2008protein}. However, experimental methods are generally limited in the level of detail they can provide about the folding process, motivating the use of MD simulations to allow atomistic insights into folding dynamics \cite{piana2014assessing}.

In molecular dynamics, the motion of atoms is propagated using classical mechanics, by integrating, e.g., Newton‚Äôs equations of motion \cite[pp.~358ff.]{santamaria2023molecular}. The forces acting on the atoms are typically obtained from a molecular mechanics force field\footnote{Since MD simulations are fully controlled by the user, the forces acting on the system do not have to correspond strictly to physical reality but can also be altered, e.g., by mixing classical mechanics with quantum mechanical effects \cite{warshel1976theoretical}.}, which provides an approximate potential energy function \cite[pp.~298ff.]{santamaria2023molecular}. As a result, running MD simulations allows us to explore the conformational space according to the Boltzmann distribution (given some assumptions, which we will discuss later), which includes folding events \cite{henin2022enhanced}. However, the exploration of conformational space is still stochastic, requiring us to run simulations for long enough. With increasing computational power \cite{salomon2013routine}, the use of specialized hardware \cite{shaw2008anton}, or highly parallelized simulations \cite{shirts2000screen}, MD simulations can access increasingly long timescales. \cite{hollingsworth2018molecular} Alternatively, enhanced sampling methods such as metadynamics \cite{laio2002escaping} or umbrella sampling \cite{torrie1977nonphysical} can be used to accelerate the exploration of rare conformations by biasing the sampling process, e.g., by adding biasing potential that guides the system over energy barriers \cite{henin2022enhanced}. However, since these methods bias the simulation, the downstream analysis of the resulting trajectories must be adapted accordingly \cite{kamenik2022enhanced}.

To extract meaningful insights from MD simulations, their trajectories must be analyzed appropriately. Some properties, such as the temperature, pressure, or distances, can be computed directly from (averages over) the frames of the trajectory. However, many properties of interest, such as free energies which determine folding pathways and their kinetics, depend not on the frames directly, but rather on the distribution of conformations they represent, i.e., the accessible conformational space. \cite[pp.~167ff.]{frenkel2002understanding} Analyzing the conformational space is non-trivial due to its high dimensionality (e.g., three spatial coordinates per atom). To enable interpretation, we can project the high-dimensional conformational space onto fewer collective variables (CVs), along which we, for example, can compute free energy surfaces (FES). \cite{fiorin2013using} Collective Variables are detailed in Section \TODO{Ref}. For extracting long-timescale kinetics, a probabilistic framework such as Markov State Models (MSMs) can be applied \cite{malmstrom2014application}. These will be discussed in detail in Section \TODO{Ref}. MSMs discretize the conformational space into distinct states, enabling the quantitative prediction of transition rates and folding pathways \cite{chodera2014markov}.

\subsection{Aim and Scope}
This work provides a literature review on computational approaches for investigating protein folding dynamics. We focus specifically on the transfer operator formalism which we summarize for the reader and afterwards leverage as a unifying link between different analysis techniques.

We examine two primary methods for extracting insight from molecular dynamics data. The first is Time-lagged Independent Component Analysis (TICA). This technique identifies the slow collective variables of a system and allows us to visualize free energy surfaces. The second method is Markov State Models (MSMs). These models discretize the simulation data to predict folding pathways and kinetic rates. We explain the intuition behind both methods and how they extract meaningful signals from noisy trajectories. Furthermore, we discuss how the variational principle of the transfer operator connects them. This perspective treats both TICA and MSMs as related tools for finding the slowest physical processes in a system.

% TODO below, change later depending on what I find and actually end up doing
Beyond biological systems, we explore a novel application of these frameworks to machine learning. We draw a parallel between molecular dynamics and neural network training. In this analogy, the network parameters move through a loss landscape much like atoms move through an energy landscape. We investigate whether tools designed for protein folding can provide insights into the training of deep learning models. % TODO -> Specifically, we treat the optimization process as a trajectory. We then test if TICA and MSMs can identify metastable parameter states or convergence pathways in the loss landscape. We demonstrate these concepts on model systems to explore how parameter settings affect the resulting dynamics.

\section{Transfer Operator Formalism}
At the end of the 1990s, the transfer operator formalism was introduced to model the dynamics of molecular systems in the context of MD simulations and thus provided a principled mathematical framework for describing MD simulations \cite{schutte2001transfer}. In this section, we summarize the key concepts of this formalism that are necessary to understand the following sections on collective variables (Section \TODO{Ref}) and Markov State Models (Section \TODO{Ref}). The notation and terminology used here follow those in \cite{prinz2011markov, perez2013identification, noe2017collective}. For more detailed explanations and in-depth derivations, the reader is referred to those references.

The possible conformations of a molecular system, in our case a (solvated) protein, span a high-dimensional state space $\Omega \subseteq \mathbb{R}^{3n}$, where $n$ is the number of atoms in the system. In some cases, the state space may be expanded to represent the full phase space by including momenta (then $\Omega \subseteq \mathbb{R}^{6n}$), but we will focus on the configuration space here. A trajectory generated by an MD simulation can be seen as a time series of points in this state space $\mathbf{x}(t) = \mathbf{x} \in \Omega$, i.e., the conformation of the system at time $t$. The dynamical process $\mathbf{x}(t)$ can be either time continuous or discrete. Since we are concerned with MD simulations, we will consider discrete time points $t = k \delta$, where $k \in \mathbb{N}_0$ and $\delta$ is the integration time step between frames. However, the transfer operator formalism will increasingly move away from individual trajectories or conformations and instead focus on probability distributions over the state space $\Omega$ at time $t$, denoted as $p_t(\mathbf{x}): \Omega \rightarrow \mathbb{R}_{0+}$. These probability distributions describe how likely the system is to occupy different regions of the state space at a given time $t$ and thus provide a statistical description of the ensemble that the MD simulation sampled from. We must impose some assumptions on the dynamical process $\mathbf{x}(t)$ to make the following formalism mathematically founded.

First, we assume that the process is \textit{Markovian} in $\Omega$. This means that the future state of the system $\mathbf{x}(t + \Delta t)$ depends only on its current state $\mathbf{x}(t)$. We can therefore define the transition probability density as:
Based on the discretization, we can define the transition probability matrix $\mathbf{T}(\tau) \in \mathbb{R}^{n \times n}$, 
\begin{equation}
    p(\mathbf{x}, \mathbf{y}; \tau) d\mathbf{y} = \mathbb{P}\left[\mathbf{x}(t + \tau) = \mathbf{y} + d\mathbf{y} | \mathbf{x}(t) = \mathbf{x}\right] \label{eq:intro:transition_prob}
\end{equation}
$p(\mathbf{x}, \mathbf{y}; \tau)$ describes the probability density of transitioning from state $\mathbf{x}$ at time $t$ to state $\mathbf{y}$ at time $t + \tau$ (note that we require $d\mathbf{y}$ since the state space is continuous and we must integrate to get probabilities). As before, we will consider discrete time points, i.e., $\tau = m \delta$ for $m \in \mathbb{N}_0$. Similarly, we can define the transition probability from a state $\mathbf{x}$ at time $t$ to a set of states $A \subset \Omega$ at time $t + \tau$ as $p(\mathbf{x}, A; \tau) = \mathbb{P}\left[\mathbf{x}(t + \tau) \in A | \mathbf{x}(t) = \mathbf{x}\right]$.

Second, we assume that the process is (sufficiently) \textit{ergodic}, meaning that all states in $\Omega$ can be reached from any other state, such that a unique stationary distribution $\mu(\mathbf{x})$ exists. The stationary distribution can be seen as the fraction of time the system spends in different regions of the state space when the simulation time approaches infinity. As mentioned in Section \ref{sec:intro:studying_folding}, the stationary distribution for molecular dynamics simulations at constant temperature is given by the Boltzmann distribution:
\begin{equation}
    \mu(\mathbf{x}) = Z^{-1} e^{-\beta H(\mathbf{x})} \label{eq:intro:boltzmann}
\end{equation}
where $Z$ is the partition function (normalization constant), $\beta = (k_B T)^{-1}$ is the inverse temperature with Boltzmann constant $k_B$ and temperature $T$, and $H(\mathbf{x})$ is the Hamiltonian of the system at conformation $\mathbf{x}$ (total energy).

Lastly, we assume that the process is \textit{reversible}. Thus, the transition probability satisfies the condition of detailed balance, i.e., when at equilibrium (the stationary distribution $\mu(\mathbf{x})$), the transition rate from state $\mathbf{x}$ to $\mathbf{y}$ is equal to the reverse direction: $\mu(\mathbf{x}) p(\mathbf{x}, \mathbf{y}; \tau) = \mu(\mathbf{y}) p(\mathbf{y}, \mathbf{x}; \tau)$. The condition of detailed balance is not necessary for, e.g., Markov State Models (Section \TODO{Ref}), but it simplifies the mathematical treatment so that we will assume it here. Generally, it is assumed that equilibrium MD simulations fulfill this condition \cite{prinz2011markov}.

Given these assumptions, we now focus on the change of the probability distribution $p_t(\mathbf{x})$ (different from $\mu(\mathbf{x})$) as the MD simulation progresses. If the system is at distribution $p_t(\mathbf{x})$ at time $t$, the distribution after lag-time $\tau$ will have changed (slowly approaching $\mu(\mathbf{x})$) since the system has evolved according to the transition probabilities $p(\mathbf{x}, \mathbf{y}; \tau)$ defined above. Mathematically, we can describe this change using the \textit{propagator operator} $\mathcal{P}(\tau)$, which advances the distribution $p_t(\mathbf{x})$ by lag-time $\tau$ to $p_{t + \tau}(\mathbf{y})$:
\begin{equation}
    p_{t + \tau}(\mathbf{y}) = \mathcal{P}(\tau) p_t(\mathbf{y}) = \int_{\mathbf{x} \in \Omega} p(\mathbf{x}, \mathbf{y}; \tau) p_t(\mathbf{x}) d\mathbf{x} \label{eq:intro:propagator}
\end{equation}
If we now consider not the probability distribution $p_t(\mathbf{x})$ directly, but rather its relative distribution with respect to the stationary distribution $\mu(\mathbf{x})$, we can define the equivalent \textit{transfer operator} $\mathcal{T}(\tau)$ as:
\begin{align}
    u_{t + \tau}(\mathbf{y}) = \mathcal{T}(\tau) u_t(\mathbf{y}) &= \frac{1}{\mu(\mathbf{y})} \int_{\mathbf{x} \in \Omega} p(\mathbf{x}, \mathbf{y}; \tau) \mu(\mathbf{x}) u_t(\mathbf{x}) d\mathbf{x} \\
    p_t(\mathbf{x}) &= \mu(\mathbf{x}) u_t(\mathbf{x}) \label{eq:intro:prop_to_transfer}
\end{align}
Because both operators $\mathcal{P}(\tau)$ and $\mathcal{T}(\tau)$ fulfill the Chapman-Kolmogorov equation, they can be applied arbitrarily often to propagate the distribution over multiple lag-times $\tau$.

The \emph{key insight} of the transfer operator formalism lies in the recognition that the eigenvalues and eigenfunctions of the propagation and transfer operators hold interpretable meanings. This is most easily seen by considering the action of the propagator operator on the stationary distribution $\mu(\mathbf{x})$. Since the system is already at equilibrium, applying the propagator does not change the distribution:
\begin{equation}
    \mathcal{P}(\tau) \mu(\mathbf{x}) = \mu(\mathbf{x}) = \phi_1(\mathbf{x})
\end{equation}
Thus, the stationary distribution $\mu(\mathbf{x})$ is an eigenfunction $\phi_1(\mathbf{x})$ of the propagator operator with eigenvalue $\lambda_1 = 1$. By Equation \ref{eq:intro:prop_to_transfer}, we can see that the corresponding eigenfunction of the transfer operator is simply the constant function $\psi_1(\mathbf{x}) = \mathbf{1}$. More generally, we can define the eigenvalue problems for both operators as:
\begin{align}
    \mathcal{P}(\tau) \phi_i(\mathbf{x}) &= \lambda_i \phi_i(\mathbf{x}) \label{eq:intro:evp_prop} \\
    \mathcal{T}(\tau) \psi_i(\mathbf{x}) &= \lambda_i \psi_i(\mathbf{x}) \label{eq:intro:evp_transfer}
\end{align}
where we can relate the eigenfunctions of both operators via $\phi_i(\mathbf{x}) = \mu(\mathbf{x}) \psi_i(\mathbf{x})$, following from Equation \ref{eq:intro:prop_to_transfer}. Importantly, the eigenvalues $\lambda_i$ are the same for both operators. If we assume reversibility, the eigenvalues are real and can be bounded by $-1 < \lambda_i \leq 1$. Following convention, we can order the eigenvalues such that $\lambda_1 = 1 > \lambda_2 \geq \lambda_3 \geq ...$. However, we only consider the biggest $m$ eigenvalues and eigenfunctions termed dominant. From the Chapman-Kolmogorov equation, it follows that the eigenvalues must follow a relation to a physically interpretable timescale $t_i$ in the form of:
\begin{equation}
    \lambda_i = e^{-\tau t_i^{-1}} \quad \Leftrightarrow \quad t_i = -\frac{\tau}{\ln \lambda_i} \label{eq:intro:timescale}
\end{equation}
These timescales $t_i$ are also referred to as the $i$th implied timescale.

Combining the above (assuming reversibility) allows us to decompose the action of the transfer operator on an arbitrary distribution $u(\mathbf{x})$ into its eigenvalues and eigenfunctions:
\begin{align}
    u_{t + k\tau}(\mathbf{x}) &= \mathcal{T}(\tau)^k u_t(\mathbf{x}) = \sum_{i=1}^{\infty} \lambda_i^k \langle u_t, \phi_i \rangle \psi_i(\mathbf{x}) \\
    &= \sum_{i=1}^{m} \lambda_i^k \langle u_t, \phi_i \rangle \psi_i(\mathbf{x}) \left[ + \mathcal{T}(\tau)^k_{\text{fast}} u_t(\mathbf{x}) \right] \label{eq:intro:transfer_decomp}
\end{align}
where $\langle u_t, \phi_i \rangle = \int_{\mathbf{x} \in \Omega} u_t(\mathbf{x}) \phi_i(\mathbf{x}) d\mathbf{x}$ is the scalar product in Dirac notation.

Equation \ref{eq:intro:transfer_decomp} allows us to interpret the dynamics in a physically meaningful way. We split the decomposition into the $m$ dominant and the remaining fast processes since we are primarily interested in the slow processes of the system, which include folding or larger conformational changes. Thus, the slow dynamics can be viewed as a linear combination of the $m$ dominant eigenfunctions. With increasing simulation time (i.e., increasing $k$), the contributions of the eigenfunctions scales exponentially with their eigenvalues. For all eigenfunctions, except the stationary, this contribution will eventually decay to zero as $k \rightarrow \infty$, returning the distribution to the stationary distribution. Larger timescales $t_i$ correspond to eigenvalues $\lambda_i$ closer to 1, thus these processes decay more slowly and represent, e.g., a distribution of meta-stable states which must overcome large energy barriers to relax to equilibrium. Faster processes have smaller eigenvalues and thus decay quickly, allowing us to approximate the long-timescale dynamics using only the $m$ dominant eigenvalues and eigenfunctions.

\subsection{Variational Approach for Approximating the Eigenvalue Problem}

As seen above, the eigenvalues and eigenfunctions of the transfer operator provide a physically interpretable description of the long-timescale dynamics of molecular systems. Therefore, we are interested in finding the solutions to the eigenvalue problem defined in Equations \ref{eq:intro:evp_prop} and \ref{eq:intro:evp_transfer}. However, we cannot solve these equations analytically for realistic molecular systems. Instead, we must resort to numerical approximations from MD data. \cite{noe2013variational} For this, we will look at two approaches in the following sections: Time-lagged Independent Component Analysis (TICA) in Section \TODO{Ref} and Markov State Models (MSMs) in Section \TODO{Ref}. How \emph{both} methods approximate the eigenvalue problem can be understood within the framework of the \textit{variational principle}, where each method is a special case of this principle \cite{noe2013variational,perez2013identification}. Here, we will only summarize the key concepts of the variational principle. For in-depth discussions, derivations, and proofs, we refer the reader to \cite{noe2013variational, perez2013identification, noe2017collective}.

In the variational approach, we approximate the eigenfunctions $\psi_i(\mathbf{x})$ of the transfer operator $\mathcal{T}(\tau)$ as linear combinations of a set of $n$ basis functions $\chi_k(\mathbf{x})$:
\begin{equation}
    \hat{\psi}_i(\mathbf{x}) = \sum_{k=1}^{n} b_{ik} \chi_k(\mathbf{x}) \label{eq:intro:var_approx}
\end{equation}
where $\hat{\psi}_i(\mathbf{x})$ is the approximation of $\psi_i(\mathbf{x})$ and $b_{ik}$ are the expansion coefficients which we can collect into a vector $\mathbf{b}_i \in \mathbb{R}^n$. The approximation of the eigenvalue problem is thus reduced to finding optimal coefficients $\mathbf{b}_i$ for each eigenfunction. Based on a generalized Ritz method \cite{ritz1909neue}, we can show that the optimal coefficients $\mathbf{b}_i$ for any basis set $\{\chi_k(\mathbf{x})\}_{k=1}^n$ can be found by solving the generalized eigenvalue problem:
\begin{equation}
    \mathbf{C}(\tau) \mathbf{b}_i = \mathbf{C}(0) \hat{\lambda}_i \mathbf{b}_i \label{eq:intro:var_evp}
\end{equation}
where $\hat{\lambda}_i$ is the approximation of $i$th eigenvalue. The matrices $\mathbf{C}(\tau)$ and $\mathbf{C}(0)$ are the covariance matrices of the basis functions at lag-time $\tau$ and 0, respectively:
\begin{align}
    c_{ij}^{\chi}(\tau) &= \langle \chi_i(\mathbf{x}(t)) \cdot \chi_j(\mathbf{x}(t + \tau)) \rangle_{t} \label{eq:intro:cov_mat_tau} \\
    c_{ij}^{\chi}(0) &= \langle \chi_i(\mathbf{x}(t)) \cdot \chi_j(\mathbf{x}(t)) \rangle_{t} \label{eq:intro:cov_mat_nill}
\end{align}
where $\langle \dots \rangle_{t}$ denotes the time average over the MD trajectory, not the scalar product. By solving Equation \ref{eq:intro:var_evp}, we can obtain the optimal coefficients $\mathbf{b}_i$ and the approximated eigenvalues $\hat{\lambda}_i$. We can therefore approximate the eigenfunctions of the transfer operator via Equation \ref{eq:intro:var_approx} as linear combinations of the basis functions. These basis functions $\chi_k(\mathbf{x}): \Omega \rightarrow \mathbb{R}$ can generally be chosen freely and can be non-linear functions of the state space, thus allowing flexibility despite a linear combination.

\section{Collective Variables and Free Energy Surfaces}
Molecular simulation data is inherently high-dimensional, as it describes the positions of all atoms in a system over time. Therefore, directly interpreting this data to extract meaningful insights is challenging. \cite{glielmo2021unsupervised} Collective Variables (CVs) provide a solution to this problem by reducing the dimensionality of the data. Specifically, CVs are functions of conformational space that map to scalar values: $\xi: \Omega \rightarrow \mathbb{R}$. \cite{henin2022enhanced} In Figure \ref{fig:intro:funnel}, we have already implicitly used a CV by plotting the free energy as a function of protein conformation. To capture meaningful aspects of the system's dynamics, CVs should ideally separate different meta-stable states and capture the slow dynamics of the system \cite{bhakat2022collective}. For example, in protein folding, an ideal CV would range from 0 (unfolded) to 1 (folded), effectively capturing the folding process and clearly separating meta-stable states along this CV. Many approaches to define CVs have been proposed, ranging from those based on chemo-physical intuition (e.g., radius of gyration \cite{ivankov2009coupling}, dihedral angles \cite{jerath2016mapping}, distances between residues \cite{taddese2020deciphering}) to data-driven methods (e.g., Principal Component Analysis (PCA) \cite{maisuradze2009principal}, Time-lagged Independent Component Analysis (TICA) \cite{schwantes2013improvements}, autoencoders \cite{belkacemi2023autoencoders}) \cite{bhakat2022collective}. CVs have been used in molecular simulations for decades, with early applications dating back to the 1970s \cite{chandler1978statistical}.

Generally, we must differentiate between CVs used for analysis, i.e., constructed after the simulation, and CVs used for enhanced sampling, i.e., defined before the simulation \cite{bonati2021deep}. If we look at CVs for analysis, we can leverage our simulation data itself to find CVs that capture the most important dynamics of the specific system we are interested in. Thus, we have a broad range of data-driven methods at our disposal. \cite{glielmo2021unsupervised} In contrast, we can also leverage CVs for enhanced sampling by biasing the simulation along them to accelerate the exploration of rare events (see Section \ref{sec:intro:studying_folding}). However, in this case, we must decide on the CVs before running the simulation, as they cannot be estimated from the simulation data itself \footnote{There are methods to refine CVs on-the-fly during the simulation, however, they are limited to the data up until any given point \cite{belkacemi2021chasing}.} \cite{stracke2024use}. In this report, we will focus on CVs for analysis. Nonetheless, extensive research efforts are also dedicated to finding CVs for enhanced sampling, with an increasing focus on machine learning approaches \cite{bhakat2022collective, glielmo2021unsupervised, henin2022enhanced}.

After defining suitable CVs, we can, e.g., compute the free energy as a function of these CVs, resulting in an approximated free energy surface (FES). The FES provides a low-dimensional representation of the energy landscape of the system, allowing us to visualize the dynamics more easily, thus giving us the ability to form intuition about the folding process. \cite{henin2022enhanced} How to accurately compute free energies from MD data is a complex topic beyond the scope of this report \cite[pp.~18ff.]{chipot2007free}. However, the key idea can be understood by rewriting the Boltzmann distribution (see Equation \ref{eq:intro:boltzmann}) and solving for the energy:
\begin{equation}
    \mu(\mathbf{x}) = Z^{-1} e^{-\beta H(\mathbf{x})} \; \Rightarrow \; - \beta^{-1} \ln \mu(\mathbf{x}) = H(\mathbf{x}) + C
\end{equation}
where $C = \beta^{-1} \ln Z$ is a constant. Thus, we can approximate the free energy if we know the probability distribution over our state space projected onto the CVs. An example FES along TICA CVs for protein folding can be found in Figure \TODO{Ref}. From the FES, we can clearly visualize the \TODO{States or something}. Importantly, we must be cautious when interpreting FES, as they are only low-dimensional projections of a high-dimensional landscape, necessarily leading to a loss of some information \cite{ahalawat2018assessment}. This can result in the so-called hysteresis problem in MD analysis, where important states or transitions are hidden \cite{lichtinger2023tackling}. More advanced tools like Markov State Models (MSMs) discussed in Section \TODO{Ref} can help interpret the dynamics more accurately. These models also often rely on CVs for discretization, where the MD data is clustered along the CVs to identify meta-stable states. \cite{konovalov2021markov}

\subsection{Time-lagged Independent Component Analysis}
One of the most common data-driven methods to define CVs is Time-lagged Independent Component Analysis (TICA) \cite{noe2017collective}. TICA was originally introduced as a signal processing technique \cite{ans1985adaptive}, however, it has found widespread application in the analysis of molecular dynamics simulations going back to 2011 \cite{naritomi2011slow}. Similar to Principal Component Analysis (PCA) \cite{pearson1901liii}, TICA seeks to find linear combinations of input features that capture important aspects of the data. However, while PCA identifies directions of maximum variance \cite{abdi2010principal}, TICA focuses on finding uncorrelated components that are maximally autocorrelated over a specified lag-time $\tau$ \cite[pp.~341ff.]{hyvarinen2001independent}. The application of TICA over PCA in MD analysis was initially motivated by the fact that principal components are not independent of each other, undermining the validity of linearly decomposing the dynamics into these components \cite{naritomi2011slow}. Later, it was shown that TICA can be understood as a special case of the variational approach for linearly approximating the eigenvalue problem of the transfer operator (see Section \TODO{Ref}) \cite{noe2013variational}. Thus, TICA is particularly well-suited for identifying the slow collective variables of molecular systems with a mathematical foundation rooted in the transfer operator formalism \cite{perez2013identification}.

Following \cite{perez2013identification}, we can show that TICA arises as a special case of the variational approach. As mentioned before, we aim to reduce the dimensionality of our spatial data $\mathbf{x}(t)$ (vector of atomic coordinates) by finding uncorrelated (Equation \ref{eq:intro:tica_cov0}) but maximally autocorrelated (at lag time $\tau$, Equation \ref{eq:intro:tica_covtau}) components, defined as:
\begin{align}
    c_{ij}^x (0) &= \langle x_i(t) \cdot x_j(t) \rangle_{t} \quad\;\;\, \stackrel{!}{=} \delta_{ij} \label{eq:intro:tica_cov0} \\
    c_{ii}^x (\tau) &= \langle x_i(t) \cdot x_i(t + \tau) \rangle_{t} \stackrel{!}{=} \text{maximal} \label{eq:intro:tica_covtau}
\end{align}
where $x_i(t)$ is the $i$th atomic coordinate component at time $t$ and $\delta_{ij}$ is the Kronecker delta. To achieve uncorrelated components (Equation \ref{eq:intro:tica_cov0}), we aim to diagonalize the covariance matrix $\mathbf{C}^x(0)$ via a linear transformation $\mathbf{W} = \left[\mathbf{w_1}, \dots, \mathbf{w_d}\right]$. Simultaneously, we want to maximize the autocorrelation at lag-time $\tau$ (Equation \ref{eq:intro:tica_covtau}) with respect to this transformation. P\'erez-Hern\'andez et al. \cite{perez2013identification} show that both objectives can be achieved by solving the generalized eigenvalue problem:
\begin{equation}
    \mathbf{C}^x(\tau) \mathbf{w}_i = \mathbf{C}^x(0) \hat{\lambda}_i \mathbf{w}_i \label{eq:intro:tica_evp}
\end{equation}
which is equivalent to the variational eigenvalue problem defined in Equation \ref{eq:intro:var_evp} when choosing the basis functions as the input coordinates themselves, i.e., $\chi_k(\mathbf{x}) = x_k$.

However, solving Equation \ref{eq:intro:tica_evp} is not trivial because some coordinates are most likely highly correlated. Therefore, the covariance matrix $\mathbf{C}^x(0)$ may be ill-conditioned, making it difficult to solve the eigenvalue problem directly. \cite{perez2013identification} The problem is typically solved in two steps via the AMUSE algorithm \cite{Tong1990AMUSE}, which first whitens the data by applying PCA and then solves a standard eigenvalue problem on the whitened data \cite{perez2013identification}. Thus, TICA gives us a powerful tool to approximate the slow eigenfunctions of the transfer operator laying the foundation for further analysis techniques such as Markov State Models (Section \TODO{Ref}).

% TODO Commute maps? From the Noe 2017 review

\section{Markov State Models and Protein Folding Kinetics}
While TICA linearly approximates the slowest eigenfunctions of the transfer operator, it is limited in its ability to provide exact quantitative kinetic insights into molecular systems. This is in part due to the projection of the full dynamics onto a low-dimensional space, as well as that linear approximations of the eigenfunctions may fall short in capturing the true eigenfunctions, especially in complex systems with non-linear dynamics. \cite{perez2013identification} To overcome these and more limitations, we can employ Markov State Models (MSMs), which discretize the state space and explicitly model transitions between these discrete states \cite{noe2008transition}. MSMs additionally give us the ability to stitch together many short simulations to approximate long-timescale dynamics (such as folding kinetics) without having to run prohibitively long simulations \cite{weber2011subspace}. Thus, MSMs are also an alternative to enhanced sampling methods briefly discussed in Section \ref{sec:intro:studying_folding} \cite{prinz2011markov}.

As we will see in the following sections, the transition matrix of an MSM directly approximates the transfer operator \cite{sarich2010approximation}. Therefore, by solving the eigenvalue problem of the transition matrix, we can obtain approximations of the eigenvalues and eigenfunctions of the transfer operator \cite{prinz2011markov}. This allows us to extract important kinetic information about the molecular system. Specifically, the eigenvalues of the transition matrix correspond to the relaxation rates of different processes in the system, allowing us to compute implied timescales for transitions between meta-stable states. The eigenfunctions provide insights into the nature of these processes, revealing which states are involved in slow transitions. Additionally, the stationary distribution of the MSM gives us thermodynamic information about the relative stability of different states. \cite{djurdjevac2012estimating,prinz2011markov} Beyond these insights, MSMs can also serve as a basis for Transition Path Theory (TPT), which allows us to compute committor probabilities (probability of reaching a target state before returning to the initial state) and fluxes (rates of transitions) between states, providing a deeper understanding of the pathways and mechanisms underlying molecular processes \cite{metzner2007transition}.

\subsection{Markov State Model Construction}
To construct an MSM from MD simulation data, we must first discretize the continuous state space into a finite set of discrete states, such as folding intermediates or meta-stable conformations \cite{pande2010everything}. Since the discretization of the state space will inevitably introduce some error, all our insights from the MSM will be approximations subject to this \textit{discretization error} \cite{prinz2011markov}. A common and intuitive approach to discretize the state space is by first reducing the dimensionality of the MD data using TICA (see Section \TODO{Ref}) \cite{konovalov2021markov} and then cluster the data in the space spanned by the linear approximation of the slowest eigenfunctions using algorithms such as k-means clustering \cite{prinz2011markov}. As a result, we can partition the state space into $n$ discrete microstates $S_i$. Each frame of the MD trajectory can then be assigned to one of these states by finding the closest cluster center compared to the conformation $\mathbf{x}$ in the frame, resulting in a discrete trajectory over the states and the class functions \cite{prinz2011markov}:
\begin{equation}
    \chi_i(\mathbf{x}) =
    \begin{cases}
        1, & \mathbf{x} \in S_i \\
        0, & \mathbf{x} \notin S_i
    \end{cases}
    \quad \forall i = 1, \dots, n \label{eq:msm:class_func}
\end{equation}

Based on the discretization, we can define the row-stochastic transition probability matrix $\mathbf{T}(\tau) \in \mathbb{R}^{n \times n}$, where $\mathbf{T}_{ij}(\tau)$ describes the probability of transitioning from state $S_i$ at time $t$ to state $S_j$ at time $t + \tau$ \cite{prinz2011markov}:
\begin{equation}
    \mathbf{T}_{ij}(\tau) = \mathbb{P}\left[\mathbf{x}(t + \tau) \in S_j | \mathbf{x}(t) \in S_i\right] \label{eq:msm:trans_ij}
\end{equation}
Given a discrete state distribution vector $\mathbf{p}(t) \in \mathbb{R}^n$ at time $t$, where $\mathbf{p}_{i}(t)$ is the probability of being in state $S_i$ at time $t$, we can propagate this distribution by lag-time $\tau$ using the transition matrix \cite{prinz2011markov}:
\begin{align}
    \mathbf{p}_{j}(t + \tau) &= \sum_{i=1}^{n} \mathbf{p}_{i}(t) \mathbf{T}_{ij}(\tau) \\
    \mathbf{p}^T(t + \tau) &= \mathbf{p}^T(t) \mathbf{T}(\tau) \label{eq:msm:trans_mat_act}
\end{align}

If we compare Equation \ref{eq:msm:trans_ij} to the definition of the general transition probability density in Equation \ref{eq:intro:transition_prob}, as well as compare the action of the transition matrix in Equation \ref{eq:msm:trans_mat_act} to the action of the propagator operator in Equation \ref{eq:intro:propagator}, we can see that the transition matrix $\mathbf{T}(\tau)$ is a discrete approximation of the propagator operator $\mathcal{P}(\tau)$. \cite{prinz2011markov} Therefore, by solving the eigenvalue problem of the transition matrix, we can obtain approximations of the eigenvalues and eigenfunctions of the transfer operator, which includes the stationary distribution:
\begin{equation}
    \mathbf{\pi}^T \mathbf{T}(\tau) = 1 \cdot \mathbf{\pi}^T \label{eq:msm:evp}
\end{equation}
where $\mathbf{\pi} \in \mathbb{R}^n$ is the stationary distribution over the discrete states, compared to $\mu(\mathbf{x})$ in the continuous case. As a result, we can recognize that MSMs are indeed a special case of the variational approach for approximating the eigenvalue problem of the transfer operator (Section \TODO{Ref}) when choosing the class indicator functions defined in Equation \ref{eq:msm:class_func} as basis functions \cite{prinz2011markov,noe2017collective,sarich2010approximation}.

So far, we have only seen the general definition of the transition matrix (Equation \ref{eq:msm:trans_ij}). Practically, we must estimate the transition matrix from the discrete trajectory obtained from the MD data $\mathbf{x}(t)$ where $t$ is discretized by the simulation time-step $\delta t$. To do so, we first define the observed count matrix $\mathbf{N}^\text{obs}(l \cdot \delta t)$:
\begin{equation}
    \mathbf{N}^\text{obs}_{ij}(l \cdot \delta t) = \sum_{t=0}^{M - l} \chi_{i}(\mathbf{x}(t)) \cdot \chi_{j}(\mathbf{x}(t + l \cdot \delta t)) \label{eq:msm:count_ij}
\end{equation}
which counts the number of observed transitions from state $S_i$ to state $S_j$ over a lag-time of $l \cdot \delta t$ (see Equation \ref{eq:msm:class_func}). \cite{prinz2011markov} Here, $M$ is the total number of frames in the MD trajectory. Similarly, we define the total count $\mathbf{N}^\text{obs}_i(l \cdot \delta t)$ over a state $S_i$ as $\mathbf{N}^\text{obs}_{i}(l \cdot \delta t) = \sum_{j=1}^{n} \mathbf{N}^\text{obs}_{ij}(l \cdot \delta t) \label{eq:msm:total_count_i}$, which counts the total number of observed transitions originating from state $S_i$. Prinz et al. \cite{prinz2011markov} show that the intuitive definition of the transition matrix elements as the ratio of observed transitions from state $S_i$ to state $S_j$ over the total observed transitions from state $S_i$ is a maximum likelihood estimator that is unbiased when approaching infinite simulation length $M \rightarrow \infty$:
\begin{equation}
    \hat{\mathbf{T}}_{ij}(l \cdot \delta t) = \frac{\mathbf{N}^\text{obs}_{ij}(l \cdot \delta t)}{\mathbf{N}^\text{obs}_{i}(l \cdot \delta t)} \label{eq:msm:trans_est}
\end{equation}
However, Prinz et al. \cite{prinz2011markov} also find that $\hat{\mathbf{T}}$ does not necessarily fulfill detailed balance, even if the underlying dynamics are reversible. If this property is desired, there are various methods to ensure reversibility in the estimated transition matrix \cite{prinz2011markov}.

Another open question when constructing an MSM is how to choose a lag-time $\tau$. One useful heuristic can be derived from the largest implied timescales $\hat{t}_2(\tau)$, which is computed from the eigenvalues $\hat{\lambda}_2(\tau)$ (Equation \ref{eq:intro:timescale}) of the estimated transition matrix $\hat{\mathbf{T}}(\tau)$ \cite{prinz2011markov}. Specifically, it can be shown that the residual between the true timescale $t_2$ and the estimate can be bounded from above:
\begin{equation}
    \hat{t}_2^{-1} - t_2^{-1} \leq - \tau^{-1} \ln \left(1 - \epsilon_2^2\right)
\end{equation}
where $\epsilon_2$ is the discretization error of the second eigenfunction. Thus, by increasing the lag-time $\tau$ or by reducing the discretization error $\epsilon_2$ (e.g., by increasing the number of states), we can reduce the error in the estimated timescale. Therefore, a common approach to choose a suitable lag-time is to determine $\tau$ by analyzing the convergence of the implied timescales as a function of $\tau$. \cite{prinz2011markov}

Finally, after constructing an MSM, we must validate it. Typically, this is done by performing a Chapman-Kolmogorov test, where we test if the MSM we constructed can at least reproduce the observed MD data itself, within statistical uncertainty. Specifically, we want to test the Chapman-Kolmogorov equation: \cite{prinz2011markov}
\begin{equation}
    \hat{\mathbf{T}}(k \tau) \stackrel{?}{\approx} \hat{\mathbf{T}}(\tau)^k
\end{equation}
There are various ways to perform this test in practice \cite{prinz2011markov,noe2009constructing,pande2010everything}, and deriving the test and uncertainty quantification is out of scope for this report. However, the Chapman-Kolmogorov test is a crucial step in validating the MSM \cite{prinz2011markov}.

% - Or what if we apply the formalism found here to the problem of training NNs. From ChatGPT: Use stochastic gradient MCMC (SGLD / SGHMC) to sample: If you want a stationary distribution ùëù ( ùúÉ ) ‚àù ùëí ‚àí ùõΩ ùêø ( ùúÉ ) p(Œ∏)‚àùe ‚àíŒ≤L(Œ∏) over parameters, use SGLD: these add calibrated Gaussian noise to gradient updates and have a known stationary distribution (under assumptions). They are exactly the analogue of Langevin / Hamiltonian dynamics in parameter space. Classic refs: Welling & Teh (SGLD) and SGHMC work. (maybe this is (koopman training) related: https://arxiv.org/pdf/2006.02361) IMPORTANT for applying TICA: "We also assume that the dynamics are statistically reversible, i.e., that the molecular system is simulated in thermal equilibrium." from https://doi.org/10.1063/1.4811489 --> Check if this is given

% Free Energy plots http://www.emma-project.org/latest/tutorials/notebooks/02-dimension-reduction-and-discretization.html

% Convergence of ùë° ùëñ ( ùúè ) t i ‚Äã (œÑ) as you increase ùúè œÑ is a standard check that your MSM is Markovian at lag ùúè œÑ

% https://en.wikipedia.org/wiki/Langevin_dynamics#:~:text=%5B10%5D-,Langevin%20Monte%20Carlo,-%5Bedit%5D --> How do define update step for Langevin dynamics plus stationary distribution is Boltzmann
\section{Application to Deep Learning Dynamics}
Training neural networks (NNs) is a complex optimization process as the loss landscape is typically high-dimensional and non-convex \cite{danilova2022recent}. To understand model behavior, and to analyze and interpret, e.g., training, researchers ideally want to visualize the loss landscape. This is for example achieved via simple PCA projections of the parameters over the course of training. \cite{antognini2018pca} However, many studies that investigate model properties and behavior in relation to the loss landscape (such as generalization) mostly do this on a case to case basis, as a unified framework for analyzing the loss landscape remains an open research question \cite{humayun2023training}. Moreover, even the effect of the loss landscape itself on model training is not fully clear yet. Early works hypothesized that local minima in the loss landscape are the main obstacle to successful training, however, later research showed that saddle points and flatness of minima seem to be more important. \cite{dauphin2014identifying} Therefore, understanding the dynamics of NN training in relation to the loss landscape remains an important research topic \cite{ren2025learning}.

In this section, we draw parallels between molecular dynamics (MD) simulations and NN training dynamics. Specifically, we think about training a NN as akin to folding a protein, where the parameters of the NN correspond to the atomic coordinates of the protein, and the loss landscape corresponds to the energy landscape. Both processes involve navigating a high-dimensional landscape to reach a favorable configuration (low loss or low energy). Given the success and mathematical foundation of MD analysis techniques such as TICA and MSMs (see Sections \TODO{Ref} and \TODO{Ref}), we aim to investigate if these tools can be applied to analyze NN training dynamics.

\subsection{Linking Molecular Dynamics and Neural Network Training}
We set out to investigate the mathematical similarities between molecular dynamics (MD) simulations and neural network (NN) training dynamics. Specifically, we want to explore if the transfer operator formalism used in MD analysis can be applied to understand NN training dynamics, and must therefore investigate if the assumptions of markovianty, ergodicity, and reversibility hold for NN training dynamics (see Section \TODO{ref}).

Neural network training is typically performed using variants of Stochastic Gradient Descent (SGD) \cite{ruder2016overview}. Previous research has shown that SGD with a constant learning rate simulates a Markovian process \cite{mandt2017stochastic}. Specifically, the update rule for SGD can be expressed as:
\begin{equation}
    \theta_{t+1} = \theta_t - \eta \nabla L(\theta_t; \mathcal{B}_t)
\end{equation}
where $\theta_t$ are the parameters at time step $t$, $\eta$ is the learning rate, $\nabla L(\theta_t; \mathcal{B}_t)$ is the gradient of the loss function computed on a mini-batch $\mathcal{B}_t$ \cite{amari1993backpropagation}. To draw the parallel to MD simulations, the SDG update rule would thus be akin to an integration scheme for simulating the dynamics of a particle in a potential energy landscape.

However, unlike MD simulations, the stochasticity in SGD arises from the random sampling of mini-batches rather than thermal fluctuations \cite{mandt2017stochastic}. An analog to a Langevin thermostat in MD simulations \cite{davidchack2009langevin} can be taken from Bayesian learning methods such as Stochastic Gradient Langevin Dynamics (SGLD). SGLD introduces noise into the training process such that its dynamics follow those of Langevin dynamics. \cite{welling2011bayesian} The update rule for SGLD is given by:
\begin{equation}
    \theta_{t+1} = \theta_t - \eta \nabla L(\theta_t; \mathcal{B}_t) + \sqrt{2 \eta} \cdot \epsilon_t \; \text{with} \; \epsilon_t \sim \mathcal{N}(0, I)
\end{equation}
where $\epsilon_t$ is Gaussian noise \cite{welling2011bayesian}. Given the Fokker-Planck equation associated with Langevin dynamics, SGLD has a known stationary distribution corresponding to the Boltzmann distribution over the loss landscape \cite{fuller1969analysis}.

Given that SGD with a constant learning rate is a Markovian process \cite{mandt2017stochastic}, constant SGLD is also Markovian, as the added noise is independent of the current state and does not break the Markovian property. Additionally, following Prinz et al. \cite{prinz2011markov}, we can reasonably assume that NN training via SGDL is sufficiently ergodic since it gives rise to a defined stationary distribution. Lastly, it remains open if the training dynamics are reversible.

Given these mathematical similarities to molecular dynamics simulations, we propose to view the training of neural networks through the lens of the transfer operator formalism. More precisely, we consider Bayesian learning methods, which do not aim for a single optimal set of parameters, but rather seek to sample from the posterior distribution over the parameters given the data, i.e., estimating the likelihood of parameters given the data \cite{chen2025interplay}. Thus, we can define the action of the propagator operator on a distribution over the parameters akin to Equation \ref{eq:intro:propagator}:
\begin{equation}
    p(\theta, t + \tau) = \mathcal{P}(\tau) p(\theta, t)
\end{equation}
where $p(\theta, t)$ is the distribution over the parameters $\theta$ at time $t$. If the assumptions of markovianty, ergodicity, and reversibility hold, we can then apply tools such as TICA and MSMs to analyze the training dynamics, potentially providing insights into training dynamics and establishing a general framework to analyze neural network training akin to MD analysis.

\subsection{Methods}
To investigate the applicability of MD analysis tools to deep learning, we performed simulations of neural network training treating the network parameters as the coordinates of a physical system. We utilized the MNIST dataset of handwritten digits \cite{deng2012mnist}.

\subsubsection{Model Architectures}
We investigated two distinct model architectures to explore different regimes of the parameter space. First, a simple Feed-Forward Network (FFN) with an input dimension of 784, a single hidden layer of 32 units, and an output dimension of 10, resulting in approximately 24k trainable parameters. Second, a tiny Convolutional Neural Network (CNN) consisting of two convolutional layers followed by a fully connected layer, totaling approximately 1k parameters.

\subsubsection{Simulation Protocol}
The training process was designed to mimic a standard MD simulation protocol consisting of minimization, equilibration, and production phases.
\begin{itemize}
    \item \textbf{Minimization (Phase 1):} The models were first trained using standard Stochastic Gradient Descent (SGD) for 20 epochs to reach a local minimum in the loss landscape. This corresponds to the energy minimization step in MD.
    \item \textbf{Equilibration (Phase 2):} We then switched to the Stochastic Gradient Langevin Dynamics (SGLD) optimizer. The system was evolved for 10,000 steps to allow the parameters to equilibrate to the stationary distribution defined by the noise scale.
    \item \textbf{Production (Phase 3):} Finally, we performed a long production run using SGLD to sample the parameter space.
\end{itemize}
The SGLD update rule used is given by:
\begin{equation}
    \theta_{t+1} = \theta_t - \eta \nabla L(\theta_t) + \sqrt{2\eta} \sigma \epsilon
\end{equation}
where $\eta$ is the learning rate, $\sigma$ is the noise scale, and $\epsilon \sim \mathcal{N}(0, I)$ is Gaussian noise.

For the CNN, we performed a production run of $2 \times 10^6$ steps, saving the system state every 25 steps. For the FFN, due to the larger parameter space, we extended the production run to $20 \times 10^6$ steps, saving every 2,000 steps. Due to computational constraints, only a single replicate was simulated for each model.

\subsubsection{Analysis}
The resulting trajectories of the network parameters $\theta(t)$ were analyzed using Principal Component Analysis (PCA) and Time-lagged Independent Component Analysis (TICA) to identify slow collective variables and visualize the dynamics in a reduced-dimensional space. The analysis was performed using the DeepTime library \cite{hoffmann2021deeptime}.

\subsection{Results and Discussion}
Despite the significant difference in the number of parameters between the FFN (24k) and the CNN (1k), both models achieved similar test accuracies of over 90\% on the MNIST dataset after the minimization phase and maintained this performance during the SGLD production runs. This indicates that both models were able to effectively learn the task and that the additional noise introduced by SGLD dynamics did not derail their performance.

If we look at the TICA projection onto the first 2 components for the FFN and CNN training trajectories (Figure \TODO{Ref}), we observe that both trajectories form distinct paths rather than point clouds, which we would expect if we sampled the loss-landscape. Specifically, we see that both trajectories exhibit a clear parabolic shape at lag-time $\tau=10$ and a circular shape at lag-time $\tau=4000$. However, it is also visible that the smaller CNN model's projections show a broader path traced out in the TICA projection compared to the FFN.

These observed shapes in the TICA projections are very similar to those reported by Schultze et al. \cite{schultze2021time} in their study of TICA applied to random walks in the context of protein folding. They find that molecular dynamics simulations that have not converged to the stationary distribution or sampled the state space sufficiently exhibit TICA projections that resemble those of random walks. Therefore, we can conclude that the training dynamics of both the FFN and CNN much more closely related to a high-dimensional random walk in parameter space rather than a meaningful exploration of the loss landscape itself, at least within the timescales we simulated.

These findings are further supported by the PCA projections of the training trajectories (Figure \TODO{Ref}). Similar to the TICA projections, we observe that both the FFN and CNN training trajectories form distinct paths in the PCA space, which aligns with findings from Antognini et al. \cite{antognini2018pca}. They show that PCA projections of high-dimensional random walks result in Lissajous curves due to the cosine-like nature of the eigenfunctions. They show this explicitly if the dimensionality of the system is much larger than the number of time steps. However, even for the CNN with only 1k parameters but 80k saved steps, we observe similar behavior, indicating that the training dynamics are dominated by random-walk-like behavior in parameter space.

The resemblance of our projected trajectories to high-dimensional random walks suggests that the system primarily underwent diffusive motion on the simulated timescales, rather than discrete transitions between meta-stable basins. Crucially, this was not due to excessive noise, as both models maintained high test accuracy ($>90\%$), indicating confinement within a valid solution manifold. Instead, the lack of structured transitions likely stems from the immense volume of the parameter space (even for the tiny CNN) requiring significantly longer sampling to observe rare events, much like in protein folding.

To the best of our knowledge, this work is the first to propose the transfer operator formalism as a framework for analyzing neural network training dynamics. Practical application is currently limited by the high dimensionality of NNs. In protein folding, systems with thousands of atoms can be effectively reduced to a few degrees of freedom by focusing on intuitive order parameters, such as backbone dihedral angles or $C_\alpha$ positions. In contrast, even for our tiny CNN with only $\approx 1000$ parameters, no such intuitive collective variables exist to filter out the high-dimensional noise. However, the transfer operator formalism could provide a solid mathematical foundation for future work on investigating NN training dynamics theoretically.

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
